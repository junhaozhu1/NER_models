# 中文命名实体识别(NER)模型对比实验框架

## 1. 项目概述

本项目是一个用于系统性比较不同中文NER模型性能的实验框架。框架采用模块化设计，支持快速添加新模型并在相同条件下进行公平对比。主要特点包括：

- **统一的数据处理流程**
- **标准化的模型接口**
- **一致的训练和评估方法**
- **灵活的配置管理**

## 2. 环境安装

### 2.1 系统要求

- Python >= 3.8
- CUDA >= 11.8 (可选，用于GPU加速)
- 内存 >= 8GB

### 2.2 安装步骤

创建并激活虚拟环境：
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows
```

安装依赖包：
```bash
pip install torch==2.4.0
pip install transformers==4.37.3
pip install numpy scikit-learn tqdm pytorch-crf
```

验证安装：
```python
import torch
print(f"PyTorch版本: {torch.__version__}")
print(f"CUDA可用: {torch.cuda.is_available()}")
```

## 3. 项目结构与代码解释

### 3.1 整体架构

```
ner_comparison/
├── data/               # 数据模块
├── models/             # 模型实现
├── train.py           # 训练脚本
├── evaluate.py        # 评估脚本
└── config.py          # 配置中心
```

### 3.2 数据处理模块 (`data/utils.py`)

#### 数据集类设计

```python
class NERDataset(Dataset):
    def __init__(self, file_path, word2idx=None, label2idx=None, max_len=128):
        self.sentences, self.labels = self.load_data(file_path)
        self.max_len = max_len
      
        # 构建词表
        if word2idx is None:
            self.word2idx = self.build_vocab(self.sentences)
        else:
            self.word2idx = word2idx
```

数据集类负责：
- 加载并解析数据文件
- 构建词表和标签映射
- 将文本转换为模型可处理的数字序列

#### 数据加载器

```python
def get_dataloader(file_path, batch_size=32, shuffle=True, **kwargs):
    dataset = NERDataset(file_path, **kwargs)
  
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        collate_fn=collate_fn,
        num_workers=4
    )
    return dataloader, dataset
```

### 3.3 模型实现 (`models/bilstm_crf.py`)

#### 模型架构

BiLSTM-CRF模型结构：

```python
class BiLSTMCRF(nn.Module):
    def __init__(self, vocab_size, num_labels, embedding_dim=100, hidden_dim=256):
        super().__init__()
        # 词嵌入层
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
      
        # 双向LSTM层
        self.bilstm = nn.LSTM(
            embedding_dim, 
            hidden_dim // 2,
            bidirectional=True,
            batch_first=True
        )
      
        # 线性映射层
        self.hidden2tag = nn.Linear(hidden_dim, num_labels)
      
        # CRF层
        self.crf = CRF(num_labels, batch_first=True)
```

#### 损失计算

模型使用CRF层计算序列标注的负对数似然损失：

```python
def loss(self, word_ids, label_ids, mask, lengths=None):
    emissions = self.forward(word_ids, mask, lengths)
    return -self.crf(emissions, label_ids, mask=mask)
```

#### 预测方法

使用维特比算法解码最优标签序列：

```python
def predict(self, word_ids, mask, lengths=None):
    emissions = self.forward(word_ids, mask, lengths)
    return self.crf.decode(emissions, mask=mask)
```

### 3.4 训练脚本 (`train.py`)

#### 混合精度训练

利用PyTorch 2.x的自动混合精度特性加速训练：

```python
use_amp = device == 'cuda' and cfg.get('use_amp', True)
scaler = GradScaler() if use_amp else None

if use_amp:
    with autocast():
        loss = model.loss(word_ids, label_ids, mask, lengths)
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

#### 学习率调度

使用StepLR调度器实现学习率衰减：

```python
scheduler = optim.lr_scheduler.StepLR(
    optimizer, 
    step_size=10, 
    gamma=0.9
)
```

#### 早停机制

通过监控验证集F1分数实现早停：

```python
if f1_score > best_f1:
    best_f1 = f1_score
    no_improve = 0
    torch.save(model.state_dict(), f'{model_name}_best.pth')
else:
    no_improve += 1
    if no_improve >= patience:
        print(f'早停：F1分数已{patience}轮未提升')
        break
```

### 3.5 评估模块 (`evaluate.py`)

#### 性能指标计算

使用sklearn计算精确率、召回率和F1分数：

```python
from sklearn.metrics import precision_recall_fscore_support

# 过滤O标签，只评估实体识别性能
entity_true = []
entity_pred = []
for t, p in zip(all_true, all_pred):
    if t != 'O' or p != 'O':
        entity_true.append(t)
        entity_pred.append(p)

precision, recall, f1, _ = precision_recall_fscore_support(
    entity_true, entity_pred, average='micro'
)
```

### 3.6 配置管理 (`config.py`)

集中管理所有模型的超参数：

```python
MODEL_CONFIGS = {
    'bilstm-crf': {
        'embedding_dim': 100,
        'hidden_dim': 256,
        'dropout': 0.5,
        'learning_rate': 0.001,
        'batch_size': 32,
        'epochs': 30
    },
    'bert-crf': {
        'bert_model': 'bert-base-chinese',
        'learning_rate': 2e-5,
        'batch_size': 16,
        'epochs': 10
    }
}
```

## 4. 使用方法

### 4.1 准备数据

数据格式要求（BIO标注）：
```
中 B-LOC
国 I-LOC
政 B-ORG
府 I-ORG
今 O
天 O
```

将数据放置在指定目录：
```bash
mkdir -p data/msra
# 将训练和测试数据复制到data/msra/目录
```

### 4.2 训练模型

基础训练命令：
```bash
# 训练BiLSTM-CRF模型
python train.py --model bilstm-crf

# 训练BERT-CRF模型
python train.py --model bert-crf
```

自定义训练参数：
```bash
python train.py --model bilstm-crf \
                --epochs 50 \
                --batch_size 64 \
                --lr 0.001
```

### 4.3 评估模型

```bash
# 评估单个模型
python evaluate.py --model bilstm-crf \
                   --checkpoint bilstm-crf_best_model.pth
```

### 4.4 批量实验

创建实验脚本`run_experiments.sh`：
```bash
#!/bin/bash
# 运行所有模型实验
for model in bilstm-crf bert-crf; do
    echo "训练模型: $model"
    python train.py --model $model
done

# 生成对比报告
python compare_results.py
```

## 5. 实验结果分析

### 5.1 性能对比

典型的实验结果对比：

| 模型 | Precision | Recall | F1-Score | 训练时间 |
|------|-----------|--------|----------|----------|
| BiLSTM-CRF | 92.3% | 91.5% | 91.9% | 30min |
| BERT-CRF | 94.8% | 93.2% | 94.0% | 2h |

### 5.2 结果可视化

生成训练曲线：
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_f1_scores, label='Validation F1')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()
plt.savefig('training_curves.png')
```

## 6. 扩展与优化

### 6.1 添加新模型

1. 在`models/`目录创建新模型文件
2. 实现统一的模型接口：
   ```python
   class NewModel(nn.Module):
       def forward(self, ...): pass
       def loss(self, ...): pass
       def predict(self, ...): pass
   ```

3. 在`config.py`添加模型配置
4. 在`train.py`中注册模型

### 6.2 性能优化建议

- **数据增强**：添加同义词替换、随机删除等
- **模型集成**：结合多个模型的预测结果
- **超参数优化**：使用Optuna等工具自动搜索
- **知识蒸馏**：用大模型指导小模型训练

## 7. 常见问题

### Q1: CUDA内存不足
```python
# 减小批次大小
config.MODEL_CONFIGS['bert-crf']['batch_size'] = 8

# 或使用梯度累积
if batch_idx % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()
```

### Q2: 训练不稳定
```python
# 添加梯度裁剪
torch.nn.utils.clip_grad_norm_(
    model.parameters(), 
    max_norm=cfg['gradient_clip']
)
```

## 8. 总结

本实验框架提供了一个标准化的中文NER模型对比平台，具有以下优势：

1. **公平性**：所有模型在相同条件下训练和评估
2. **可扩展性**：易于添加新模型和数据集
3. **可重现性**：固定的随机种子和详细的配置记录
4. **易用性**：简洁的命令行接口和清晰的代码结构
